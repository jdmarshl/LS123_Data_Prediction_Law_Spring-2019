{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Legal Studies 123\n",
    "# Lab 12: Intro to scikit-learn\n",
    "\n",
    "<img src=\"https://www.cityofberkeley.info/uploadedImages/Public_Works/Level_3_-_Transportation/DSC_0637.JPG\" style=\"width: 500px; height: 275px;\" />\n",
    "---\n",
    "\n",
    "** Regression** is useful for predicting a value that varies on a continuous scale from a bunch of features. This lab will introduce the regression methods available in the scikit-learn extension to scipy, focusing on ordinary least squares linear regression, LASSO, and Ridge regression.\n",
    "\n",
    "*Estimated Time: 45 minutes*\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "### Table of Contents\n",
    "\n",
    "\n",
    "1 - [The Test-Train-Validation Split](#section 1)<br>\n",
    "\n",
    "2 - [Linear Regression](#section 2)<br>\n",
    "\n",
    "3 - [LASSO Regression](#section 3)<br>\n",
    "\n",
    "4 - [Ridge Regression](#section 4)<br>\n",
    "\n",
    "5 - [Choosing a Model](#section 5)<br>\n",
    "\n",
    "\n",
    "\n",
    "**Dependencies:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# from datascience import *\n",
    "import datetime as dt\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import Ridge, Lasso, LinearRegression\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Data: Bike Sharing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In your time at Cal, you've probably passed by one of the many bike sharing station around campus. Bike sharing systems have become more and more popular as traffic and concerns about global warming rise. This lab's data describes one such bike sharing system in Washington D.C., from [UC Irvine's Machine Learning Repository](https://archive.ics.uci.edu/ml/datasets/Bike+Sharing+Dataset)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Series' object has no attribute 'strftime'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-8762a23f94fe>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# reformat the date column to integers representing the day of the year, 001-366\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mbike\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'dteday'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_datetime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbike\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'dteday'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrftime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'%j'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbike\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# get rid of the index column\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   4370\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_can_hold_identifiers_and_holds_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4371\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4372\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4373\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4374\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Series' object has no attribute 'strftime'"
     ]
    }
   ],
   "source": [
    "bike=pd.read_csv('data/Bike-Sharing-Dataset/day.csv')\n",
    "\n",
    "# reformat the date column to integers representing the day of the year, 001-366\n",
    "bike['dteday'] = pd.to_datetime(bike['dteday'])\n",
    ".strftime('%j')\n",
    "print(bike[:4])\n",
    "# get rid of the index column\n",
    "# bike = bike.drop(0)\n",
    "\n",
    "# bike[:4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take a moment to get familiar with the data set. In data science, you'll often hear rows referred to as **records** and columns as **features**. Before you continue, make sure you can answer the following:\n",
    "\n",
    "- How many records are in this data set?\n",
    "- What does each record represent?\n",
    "- What are the different features?\n",
    "- How is each feature represented? What values does it take, and what are the data types of each value?\n",
    "\n",
    "Use Table methods and check the UC Irvine link for more information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# explore the data set here\n",
    "num_records = bike.num_rows     # number of records is number of rows\n",
    "features = bike.labels\n",
    "print(num_records, ' records', ' with variables ', features)\n",
    "print('type for features', type(features))\n",
    "print(bike.hist('windspeed'))\n",
    "print(bike.hist('weekday'))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 1. The Test-Train-Validation Split  <a id='section 1'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we train a model on a data set, we run the risk of [**over-fitting**](http://scikit-learn.org/stable/auto_examples/model_selection/plot_underfitting_overfitting.html). Over-fitting happens when a model becomes so complex that it makes very accurate predictions for the data it was trained on, but it can't generalize to make good predictions on new data.\n",
    "\n",
    "We can reduce the risk of overfitting by using a **test-train split**. \n",
    "\n",
    "1. Randomly divide our data set into two smaller sets: one for training and one for testing\n",
    "2. Train the data on the training set, changing our model along the way to increase accuracy\n",
    "3. Test the data's predictions using the test set.\n",
    "\n",
    "Scikit-learn's [`test_train_split`](http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html) function will help here. First, separate your data into two parts: a Table containing the features used to make our prediction, and an array of the true values. To start, let's predict the *total number of riders* (y) using *every feature that isn't a rider count* (X).\n",
    "\n",
    "Note: for the function to work, X can't be a Table. Save X as a pandas DataFrame by calling `.to_df()` on the feature Table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the features used to predict riders\n",
    "# features_only = bike.select('dteday', 'season', 'yr', 'mnth', 'holiday', 'weekday',\n",
    "#                           'workingday', 'weathersit', 'temp', 'atemp', 'hum', 'windspeed')\n",
    "X = bike.drop('casual', 'registered', 'cnt')\n",
    "X = features_only.to_df()\n",
    "print('type X: ', type(X))\n",
    "# the number of riders\n",
    "y = bike['cnt']\n",
    "funny_y = bike.select('cnt').to_array()\n",
    "print('type y: ', type(y))\n",
    "print('type funny_y: ', type(funny_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y[0:4])\n",
    "print(funny_y[0:4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, set the random seed using `np.random.seed(...)`. This will affect the way numpy pseudo-randomly generates the numbers it uses to decide how to split the data into training and test sets. Any seed number is fine- the important thing is to document the number you used in case we need to recreate this pseudorandom split in the future.\n",
    "\n",
    "Then, call `train_test_split` on your X and y. Also set the parameters `train_size=` and `test_size=` to set aside 80% of the data for training and 20% for testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the random seed\n",
    "\n",
    "np.random.seed(10)\n",
    "\n",
    "# split the data\n",
    "# train_test_split returns 4 values: X_train, X_test, y_train, y_test\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, train_size=0.80, test_size=0.20)\n",
    "print(X_train.describe())\n",
    "print(X_test.describe())\n",
    "#print(y_train.describe())\n",
    "#print(y_test.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Validation Set\n",
    "\n",
    "Our test data should only be used once: after our model has been selected, trained, and tweaked. Unfortunately, it's possible that in the process of tweaking our model, we could still overfit it to the training data and only find out when we return a poor test data score. What then?\n",
    "\n",
    "A **validation set** can help here. By trying your trained models on a validation set, you can (hopefully) weed out models that don't generalize well.\n",
    "\n",
    "Call `train_test_split` again, this time on your X_train and y_train. We want to set aside 25% of the data to go to our validation set, and keep the remaining 75% for our training set.\n",
    "\n",
    "Note: This means that out of the original data, 20% is for testing, 20% is for validation, and 60% is for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the data\n",
    "# Returns 4 values: X_train, X_validate, y_train, y_validate\n",
    "\n",
    "X_train, X_validate, y_train, y_validate = train_test_split(X_train, y_train, train_size=0.75, test_size=0.25)\n",
    "print(X_train.describe())\n",
    "print(X_validate.describe())\n",
    "#print(y_train.describe())\n",
    "#print(y_validate.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Linear Regression (Ordinary Least Squares) <a id='section 2'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we're ready to start training models and making predictions. We'll start with a **linear regression** model.\n",
    "\n",
    "[Scikit-learn's linear regression](http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html#sklearn.linear_model.LinearRegression.score) is built around scipy's ordinary least squares, which you used in the last lab. The syntax for each scikit-learn model is very similar:\n",
    "1. Create a model by calling its constructor function. For example, `LinearRegression()` makes a linear regression model.\n",
    "2. Train the model on your training data by calling `.fit(train_X, train_y)` on the model\n",
    "\n",
    "Create a linear regression model in the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a model\n",
    "linear_bike = LinearRegression()\n",
    "# fit the model\n",
    "linear_bike.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the model fit, you can look at the best-fit slope for each feature using `.coef_`, and you can get the intercept of the regression line with `.intercept_`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# examine the coefficients and intercept\n",
    "print('coefficients: ', linear_bike.coef_)\n",
    "print('intercept: ', linear_bike.intercept_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's get a sense of how good our model is. We can do this by looking at the difference between the predicted values and the actual values, also called the error.\n",
    "\n",
    "We can see this graphically using a scatter plot.\n",
    "\n",
    "- Call `.predict(X)` on your linear regression model, using your training X and training y, to return a list of predicted number of riders per hour. Save it to a variable `lin_pred`.\n",
    "- Using a scatter plot (`plt.scatter(...)`), plot the predicted values against the actual values (`y_train`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict the number of riders\n",
    "lin_pred = linear_bike.predict(X_train)\n",
    "\n",
    "# plot the residuals on a scatter plot\n",
    "plt.scatter(y_train, lin_pred)\n",
    "plt.title('Linear Model (OLS)')\n",
    "plt.xlabel('actual value')\n",
    "plt.ylabel('predicted value')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question: what should our scatter plot look like if our model was 100% accurate?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ANSWER:**     <br>\n",
    "If the model predicted perfectly, you would get a straight line. But the scatterplot shows that the prediction using all the features did a really good job of predicting the y value in the training data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also get a sense of how well our model is doing by calculating the **root mean squared error**. The root mean squared error (RMSE) represents the average difference between the predicted and the actual values.\n",
    "\n",
    "To get the RMSE:\n",
    "- subtract each predicted value from its corresponding actual value (the errors)\n",
    "- square each error (this prevents negative errors from cancelling positive errors)\n",
    "- average the squared errors\n",
    "- take the square root of the average (this gets the error back in the original units)\n",
    "\n",
    "Write a function `rmse` that calculates the mean squared error of a predicted set of values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting root mean squared error from training data\n",
    "def rmse(pred, actual):\n",
    "       return np.sqrt(np.mean((actual-pred)**2))\n",
    "\n",
    "rmse(lin_pred, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now calculate the mean squared error for your linear model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the rmse\n",
    "rmse(lin_pred, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Ridge Regression <a id='section 3'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that you've gone through the process for OLS linear regression, it's easy to do the same for [**Ridge Regression**](http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Ridge.html). In this case, the constructor function that makes the model is `Ridge()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make and fit a Ridge regression model\n",
    "ridge_bike = Ridge()\n",
    "ridge_bike.fit(X_train, y_train)\n",
    "\n",
    "# show the coefficients and intercept for the ridge regression model\n",
    "print('coefficients: ', ridge_bike.coef_)\n",
    "print('intercept: ', ridge_bike.intercept_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use the model to make predictions\n",
    "ridge_pred = ridge_bike.predict(X_train)\n",
    "\n",
    "# plot the predictions\n",
    "plt.scatter(y_train, ridge_pred)\n",
    "plt.title('Ridge Regression Model')\n",
    "plt.xlabel('actual value')\n",
    "plt.ylabel('predicted value')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the rmse for the Ridge model\n",
    "rmse(ridge_pred, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: the documentation for Ridge regression shows it has lots of **hyperparameters**: values we can choose when the model is made. Now that we've tried it using the defaults, look at the [documentation](http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Ridge.html) and try changing some parameters to see if you can get a lower RMSE (`alpha` might be a good one to try)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make and fit a new Ridge regression model\n",
    "newridge_bike = Ridge(alpha=0.5)\n",
    "newridge_bike.fit(X_train, y_train)\n",
    "\n",
    "# show the coefficients and intercept for the ridge regression model\n",
    "print('coefficients: ', newridge_bike.coef_)\n",
    "print('intercept: ', newridge_bike.intercept_)\n",
    "\n",
    "# use the model to make predictions\n",
    "newridge_pred = newridge_bike.predict(X_train)\n",
    "\n",
    "# plot the predictions\n",
    "plt.scatter(y_train, newridge_pred)\n",
    "plt.title('New Ridge Regression Model')\n",
    "plt.xlabel('actual value')\n",
    "plt.ylabel('predicted value')\n",
    "plt.show()\n",
    "\n",
    "# calculate root mean square error\n",
    "print('new ridge regression model mean sq error: ',rmse(newridge_pred, y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(newridge_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. LASSO Regression <a id='section 4'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we'll try using [LASSO regression](http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Lasso.html). The constructor function to make the model is `Lasso()`. \n",
    "\n",
    "You may get a warning message saying the objective did not converge. The model will still work, but to get convergence try increasing the number of iterations (`max_iter=`) when you construct the model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create and fit the LASSO model\n",
    "lasso_bike = Lasso(max_iter=10000)\n",
    "lasso_bike.fit(X_train, y_train)\n",
    "\n",
    "# show the coefficients and intercept for the ridge regression model\n",
    "print('coefficients: ', lasso_bike.coef_)\n",
    "print('intercept: ', lasso_bike.intercept_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use the model to make predictions\n",
    "lasso_pred = lasso_bike.predict(X_train)\n",
    "\n",
    "# plot the predictions\n",
    "plt.scatter(y_train, lasso_pred)\n",
    "plt.title('Lasso Regression Model')\n",
    "plt.xlabel('actual value')\n",
    "plt.ylabel('predicted value')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the rmse for the LASSO model\n",
    "print('type lasso_pred', type(lasso_pred))\n",
    "print('type y_train', type(y_train))\n",
    "#lasso_pred_df = pd.DataFrame(lasso_pred)\n",
    "# y_train_array = pd.DataFrame(y_train).as_matrix()\n",
    "#print(lasso_pred_df.describe())\n",
    "rmse(lasso_pred, y_train) # why did I have to turn y_train from dataframe into numpy array? \n",
    "## because of the way I got the y values out of the original datascience Table\n",
    "# why was my rmse so different from solution set?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: LASSO regression also has many tweakable hyperparameters. See how changing them affects the accuracy!\n",
    "\n",
    "Question: How do these three models compare on performance? What sorts of things could we do to improve performance?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ANSWER:** They perform pretty similarly, if root mean square error is the measure of performance. But they all perform similarly, except Lasso seems to have a larger rmse without tweaking the parameters. That may improve the performance of Lasso model. The linear model seems just fine.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 5.  Choosing a model <a id='section 5'></a>\n",
    "### Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once you've tweaked your models' hyperparameters to get the best possible accuracy on your training sets, we can compare your models on your validation set. Make predictions on `X_validate` with each one of your models, then calculate the RMSE for each set of predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make predictions for each model using validation data\n",
    "\n",
    "# linear prediction of number of riders on validation set\n",
    "lin_pred_v = linear_bike.predict(X_validate)\n",
    "# plot the predictions on a scatter plot\n",
    "plt.scatter(y_validate, lin_pred_v)\n",
    "plt.title('Linear Model (OLS) Validation Set')\n",
    "plt.xlabel('actual value')\n",
    "plt.ylabel('predicted value')\n",
    "print(plt.show())\n",
    "\n",
    "# ridge prediction of number of riders on validation set\n",
    "ridge_pred_v = ridge_bike.predict(X_validate)\n",
    "# plot the predictions\n",
    "plt.scatter(y_validate, ridge_pred_v)\n",
    "plt.title('Ridge Regression Model Validation Set')\n",
    "plt.xlabel('actual value')\n",
    "plt.ylabel('predicted value')\n",
    "print(plt.show())\n",
    "\n",
    "# lasso\n",
    "lasso_pred_v = lasso_bike.predict(X_validate)\n",
    "# plot the predictions\n",
    "plt.scatter(y_validate, lasso_pred_v)\n",
    "plt.title('Lasso Regression Model Validation Set')\n",
    "plt.xlabel('actual value')\n",
    "plt.ylabel('predicted value')\n",
    "print(plt.show())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate RMSE for each set of validation predictions\n",
    "print('rmse linear model: ', rmse(lin_pred_v, y_validate))\n",
    "print('rmse ridge model: ', rmse(ridge_pred_v, y_validate))\n",
    "# y_validate_array = pd.DataFrame(y_validate).as_matrix()\n",
    "print(type(y_validate))\n",
    "print('rmse lasso model: ', rmse(lasso_pred_v, y_validate))\n",
    "# same problem here; have to change y_validate data type and then get a much bigger standard erro"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How do the RMSEs for the validation data compare to those for the training data? Why?\n",
    "They look like they did a little better, actually, on the validation data. That strikes me as odd unless regularization really matters that much\n",
    "\n",
    "Did the model that performed best on the training set also do best on the validation set? No, Lasso has the lowest rmse on the validation set but linear did on the training set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**YOUR ANSWER:** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predicting the Test Set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, select one final model to make predictions for your test set. This is often the model that performed best on the validation data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make predictions for the test set using one model of your choice\n",
    "# lasso\n",
    "lasso_pred_t = lasso_bike.predict(X_test)\n",
    "# plot the predictions\n",
    "plt.scatter(y_test, lasso_pred_t)\n",
    "plt.title('Lasso Regression Model Validation Set')\n",
    "plt.xlabel('actual value')\n",
    "plt.ylabel('predicted value')\n",
    "print(plt.show())\n",
    "\n",
    "# calculate the rmse for the final predictions\n",
    "print('rmse lasso model test data: ', rmse(lasso_pred_t, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Coming up this semester: how to select your models, model parameters, and features to get the best performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "Notebook developed by: Keeley Takimoto\n",
    "\n",
    "Data Science Modules: http://data.berkeley.edu/education/modules\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
