{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [LEGALST-190] Lab 4/3: Neural Nets\n",
    "\n",
    "In this lab, we'll learn how to implement neural net methods to pattern recognize handwriting images.\n",
    "\n",
    "\n",
    "*Estimated Time: 30-40 minutes*\n",
    "\n",
    "---\n",
    "### Table of Contents\n",
    "\n",
    "[The Data](#section data)<br>\n",
    "\n",
    "1 - [Visualizing Data](#section 1)<br>\n",
    "\n",
    "2 - [Neural Network](#section 2)<br>\n",
    "\n",
    "3 - [Multi-Layer Perceptrons](#section 3)<br>\n",
    "\n",
    "4 - [A Simple MLP](#section 4)<br>\n",
    "\n",
    "5 - [Convolutional Nerual Networks](#section 5)<br>\n",
    "\n",
    "**Dependencies:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting package metadata: done\n",
      "Solving environment: done\n",
      "\n",
      "## Package Plan ##\n",
      "\n",
      "  environment location: /Users/jmarshall/anaconda3\n",
      "\n",
      "  added / updated specs:\n",
      "    - keras\n",
      "\n",
      "\n",
      "The following packages will be downloaded:\n",
      "\n",
      "    package                    |            build\n",
      "    ---------------------------|-----------------\n",
      "    _tflow_select-2.3.0        |              mkl           3 KB\n",
      "    absl-py-0.7.0              |           py36_0         156 KB\n",
      "    astor-0.7.1                |           py36_0          43 KB\n",
      "    c-ares-1.15.0              |       h1de35cc_1          81 KB\n",
      "    conda-4.6.12               |           py36_1         2.1 MB\n",
      "    gast-0.2.2                 |           py36_0         138 KB\n",
      "    grpcio-1.16.1              |   py36h044775b_1         944 KB\n",
      "    keras-2.2.4                |                0           5 KB\n",
      "    keras-applications-1.0.7   |             py_0          33 KB\n",
      "    keras-base-2.2.4           |           py36_0         457 KB\n",
      "    keras-preprocessing-1.0.9  |             py_0          35 KB\n",
      "    libprotobuf-3.6.1          |       hd9629dc_0         3.8 MB\n",
      "    markdown-3.0.1             |           py36_0         107 KB\n",
      "    mock-2.0.0                 |   py36hd48142b_0         104 KB\n",
      "    pbr-5.1.3                  |             py_0          74 KB\n",
      "    protobuf-3.6.1             |   py36h0a44026_0         608 KB\n",
      "    tensorboard-1.13.1         |   py36haf313ee_0         3.3 MB\n",
      "    tensorflow-1.13.1          |mkl_py36haf07a9b_0           5 KB\n",
      "    tensorflow-base-1.13.1     |mkl_py36hc36dc97_0        94.0 MB\n",
      "    tensorflow-estimator-1.13.0|             py_0         205 KB\n",
      "    termcolor-1.1.0            |           py36_1           7 KB\n",
      "    ------------------------------------------------------------\n",
      "                                           Total:       106.2 MB\n",
      "\n",
      "The following NEW packages will be INSTALLED:\n",
      "\n",
      "  _tflow_select      pkgs/main/osx-64::_tflow_select-2.3.0-mkl\n",
      "  absl-py            pkgs/main/osx-64::absl-py-0.7.0-py36_0\n",
      "  astor              pkgs/main/osx-64::astor-0.7.1-py36_0\n",
      "  c-ares             pkgs/main/osx-64::c-ares-1.15.0-h1de35cc_1\n",
      "  gast               pkgs/main/osx-64::gast-0.2.2-py36_0\n",
      "  grpcio             pkgs/main/osx-64::grpcio-1.16.1-py36h044775b_1\n",
      "  keras              pkgs/main/osx-64::keras-2.2.4-0\n",
      "  keras-applications pkgs/main/noarch::keras-applications-1.0.7-py_0\n",
      "  keras-base         pkgs/main/osx-64::keras-base-2.2.4-py36_0\n",
      "  keras-preprocessi~ pkgs/main/noarch::keras-preprocessing-1.0.9-py_0\n",
      "  libprotobuf        pkgs/main/osx-64::libprotobuf-3.6.1-hd9629dc_0\n",
      "  markdown           pkgs/main/osx-64::markdown-3.0.1-py36_0\n",
      "  mock               pkgs/main/osx-64::mock-2.0.0-py36hd48142b_0\n",
      "  pbr                pkgs/main/noarch::pbr-5.1.3-py_0\n",
      "  protobuf           pkgs/main/osx-64::protobuf-3.6.1-py36h0a44026_0\n",
      "  tensorboard        pkgs/main/osx-64::tensorboard-1.13.1-py36haf313ee_0\n",
      "  tensorflow         pkgs/main/osx-64::tensorflow-1.13.1-mkl_py36haf07a9b_0\n",
      "  tensorflow-base    pkgs/main/osx-64::tensorflow-base-1.13.1-mkl_py36hc36dc97_0\n",
      "  tensorflow-estima~ pkgs/main/noarch::tensorflow-estimator-1.13.0-py_0\n",
      "  termcolor          pkgs/main/osx-64::termcolor-1.1.0-py36_1\n",
      "\n",
      "The following packages will be UPDATED:\n",
      "\n",
      "  conda                    conda-forge::conda-4.6.12-py36_0 --> pkgs/main::conda-4.6.12-py36_1\n",
      "\n",
      "\n",
      "Proceed ([y]/n)? "
     ]
    }
   ],
   "source": [
    "# !conda install -c tensorflow keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## The Data <a id='data'></a>\n",
    "\n",
    "In this notebook, you'll be working with the MNIST handwriting dataset, considered \"hello, world\" of object recognition in machine learning. It contains images of handwritten digits centered and normalized. Modified NIST (National Institute of Standards and Technology) is constructed from scanned documents available from NIST. \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing Data  <a id='section 1'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Keras deep learning library provides a convenience method for loading the MNIST dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://s3.amazonaws.com/img-datasets/mnist.npz\n",
      "11493376/11490434 [==============================] - 6s 1us/step\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import mnist\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy\n",
    "\n",
    "# load the MNIST dataset\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see above, the dataset is split into a set to train our model and one to test it. X_train and X_test are inputs while y_train and y_test are outputs.\n",
    "\n",
    "Let's visualize MNIST dataset by running the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot 4 images as gray scale\n",
    "plt.subplot(221)\n",
    "plt.imshow(X_train[0], cmap=plt.get_cmap('gray'))\n",
    "plt.subplot(222)\n",
    "plt.imshow(X_train[1], cmap=plt.get_cmap('gray'))\n",
    "plt.subplot(223)\n",
    "plt.imshow(X_train[2], cmap=plt.get_cmap('gray'))\n",
    "plt.subplot(224)\n",
    "plt.imshow(X_train[3], cmap=plt.get_cmap('gray'))\n",
    "# show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network <a id='section 2'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Neural networks are a set of algorithms, modeled loosely after the human brain, that are designed to recognize patterns.\n",
    "\n",
    "Neural networks help us cluster and classify. They group unlabeled data according to similarities among the example inputs.\n",
    "\n",
    "Classification problems depend on labeled datasets, i.e. humans need to label the data for a neural to learn the correlation between labels and data. This is <i>supervised learning</i>. Below, we'll dive into MLP, which utilizes a supervised learning technique."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi-Layer Perceptrons <a id='section 3'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A multi-layer perceptron (MLP) is a class of neural network that consists of at least three layers of nodes (first layer being inputs and last layer being outputs). Except for the input layer, activation of nodes of a certain layer depends on which nodes are activated in the previous layer. Each node is a neuron that uses a nonlinear activation function. Below is an image that represents a MLP."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<img src=\"https://www.safaribooksonline.com/library/view/getting-started-with/9781786468574/graphics/B05474_04_05.jpg\" style=\"width: 500px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A multilayer perceptron (MLP) is a deep, artificial neural network. They are composed of an input layer to receive the signal, an output layer that makes a decision or prediction about the input, and in between those two, an arbitrary number of hidden layers that are the true computational engine of the MLP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MLPs train on a set of input-output pairs and learn to model the correlation between those inputs and outputs by adjusting parameters to minimize error."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A Simple MLP <a id='section 4'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try to build a simple MLP to identify digits."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Input vs. Output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Each pixel of an image will be an input to our MLP.\n",
    "\n",
    "<b>Question:</b> How many nodes would our MLP's first layer have for a 20x20 image?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<i>Your answer here</i>  <b>Answer: 400</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output layer will produce what we are looking for.\n",
    "\n",
    "<b>Question:</b> What will each node in the output layer represent?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<i>Your answer here</i> <b>Answer: Each node represents a digit from 0-9</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fixing MNIST"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The training dataset is a 3-D array of instance, image width, image height. To make an image \"inputable\" to our MLP, we need to vectorize the representations of MNIST training dataset, i.e. we need to flatten a image into a vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "784"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_pixels = X_train.shape[1] * X_train.shape[2]\n",
    "num_pixels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NumPy's reshape function can help flatten multi-dimensional arrays\n",
    "# As all images are 28x28 pixels, we flatten all into vectors of length 784\n",
    "X_train = X_train.reshape(X_train.shape[0], num_pixels)\n",
    "X_test = X_test.reshape(X_test.shape[0], num_pixels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The pixel values are grey scale, which ranges from 0-255. Neural network models work better with normalized inputs. Thus, normalize our training dataset below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train / 255\n",
    "X_test = X_test / 255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The outputs (y_train and y_test) are integers from 0 to 9 and we can think fo each integer as a class. We'll use a one-hot encoding of the class values, which transforms the output vector into a binary matrix.\n",
    "\n",
    "<i>One-hot encoding is a process by which categorical variables are converted into a form that could be provided to ML algorithms to do a better job in prediction.</i>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use built-in function in np_utils\n",
    "from keras.utils import np_utils\n",
    "\n",
    "y_train = np_utils.to_categorical(y_train)\n",
    "y_test = np_utils.to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just to make sure that we still have 10 classes(0-9) after one-hot encoding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_classes = y_test.shape[1]\n",
    "num_classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keras has useful methods we can utilize to develop an MLP."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing the methods we need\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create an empty MLP, i.e. empty linear stack of layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create an input layer using the Dense function (refer to <a href=\"https://keras.io/layers/core/\">this doc</a>), then add the layer to our model using `model.add(...)`. The input layer should use 'relu' activation, a 'normal' kernel_initializer, and the number of pixels for input_dim. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/jmarshall/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Dense(...) creates a regular densely connected layer. \n",
    "relu is a rectifier activation function.\n",
    "\"\"\"\n",
    "model.add(\n",
    "    Dense(num_pixels, input_dim=num_pixels, kernel_initializer='normal', activation='relu')\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add in the output layer to our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "A softmax activation function is used on the output layer to turn the outputs into \n",
    "probability-like values\n",
    "\"\"\"\n",
    "model.add(\n",
    "    Dense(num_classes, kernel_initializer='normal', activation='softmax')\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compile our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "categorical_crossentropy is a logarithmic loss function and\n",
    "adam is a gradient descent algorithm\n",
    "\"\"\"\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now fit our model on the training dataset. We fit our model over 10 epochs and update it every 200 images. It might take a few minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/jmarshall/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 14s - loss: 0.2806 - acc: 0.9202 - val_loss: 0.1381 - val_acc: 0.9601\n",
      "Epoch 2/10\n",
      " - 11s - loss: 0.1115 - acc: 0.9678 - val_loss: 0.0930 - val_acc: 0.9725\n",
      "Epoch 3/10\n",
      " - 11s - loss: 0.0709 - acc: 0.9791 - val_loss: 0.0836 - val_acc: 0.9737\n",
      "Epoch 4/10\n",
      " - 11s - loss: 0.0496 - acc: 0.9859 - val_loss: 0.0743 - val_acc: 0.9771\n",
      "Epoch 5/10\n",
      " - 11s - loss: 0.0369 - acc: 0.9896 - val_loss: 0.0709 - val_acc: 0.9783\n",
      "Epoch 6/10\n",
      " - 12s - loss: 0.0281 - acc: 0.9919 - val_loss: 0.0721 - val_acc: 0.9773\n",
      "Epoch 7/10\n",
      " - 11s - loss: 0.0213 - acc: 0.9944 - val_loss: 0.0670 - val_acc: 0.9796\n",
      "Epoch 8/10\n",
      " - 11s - loss: 0.0145 - acc: 0.9966 - val_loss: 0.0600 - val_acc: 0.9810\n",
      "Epoch 9/10\n",
      " - 11s - loss: 0.0116 - acc: 0.9974 - val_loss: 0.0682 - val_acc: 0.9792\n",
      "Epoch 10/10\n",
      " - 11s - loss: 0.0083 - acc: 0.9984 - val_loss: 0.0617 - val_acc: 0.9820\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0xb405df860>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=10, batch_size=200, verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparing the log of our training produced above, what can you conclude?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<i>Your Answer Here</i>  **__It looks like the accuracy of the classifier improves rapidly after the first couple of iterations but then is about as accurate as it gets. Does it always converge after 8 or so iterations?__**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's evaluate our model on the test dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: 1.80%\n"
     ]
    }
   ],
   "source": [
    "scores = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(\"Error: %.2f%%\" % (100-scores[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convolutional Neural Networks <a id='section 5'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MLPs did give us pretty good accuracy. However, As each pixel of an image is an input, we will have too many inputs for a large image. Convolutional neural nets, on the other hand, can take in 3-D inputs (2D + color) instead of just 1-D."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How a CNN works <a id='conv_image'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://www.mathworks.com/content/mathworks/www/en/discovery/convolutional-neural-network/jcr:content/mainParsys/image_copy.adapt.full.high.jpg/1517522275430.jpg\" style=\"width: 600px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Filtering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ConvNets have \"features\" and match them with parts of an image rather than the whole thing. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./imgs/match_pieces.png\" style=\"width: 500px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the example above, we have three features: left-to-right diagonal, central X, and right to left diagonal. To match features, we use a process called filtering."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Assign each black pixel -1 and each white pixel 1. \n",
    "2. Line up a feature with an image patch (for example, line up left-to-right diagonal with the green box above)\n",
    "3. Multiply each feature pixel with the corresponding image patch pixel\n",
    "4. Take the average of the products"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Question:</b> In the example above when we match the left-to-right diagonal feature with the green box, what would the process output?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<i>Your Answer Here</i> <b>Answer: 1</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convolutional Layer\n",
    " \n",
    "The process of filtering for every possible image patch with every feature."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./imgs/convolution.png\" style=\"width: 500px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see in the image above, after applying our left-to-right diagonal filter, we get higher scores on the left to right diagonal."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Question:</b> If we apply the central X filter in this example, where will the highest score occur?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<i>Your Answer Here</i> <b>Answer: The very center of the entire image</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ReLU (Rectified Linear Units)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This process is applied on filtered images. It simply changes every negative value to 0 and leaves positive values unchanged."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pooling Layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this layer, we shrink the filtered images by the following process:\n",
    "1. Pick a window size and a stride size\n",
    "2. Walk our window on the filtered image, each time shifting by the stride size\n",
    "3. For each step, take the maximum score contained in the window"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./imgs/pooling.png\" style=\"width: 500px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This layer helps because it does not care about where in the window the maximum value occurs, i.e. it's less sensitive to specific positioning of pixels."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Question:</b> How would the pooling layer help in classifying digits? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<i>Your Answer Here</i> <b>Answer: Handwritten digits follow a general pattern but where each pixel lands can be undeterminstic. Matching parts of an image can tell us which general pattern occurs without caring too much about where it occurs.</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fully Connected Layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This layer flattens the pooled images and each value gets a vote, which is how strongly that value suggests a certain outcome."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One question you might have now is where do the initial features and voting weights come from. They are obtained by a process called <a href=\"https://brilliant.org/wiki/backpropagation/\">backpropragation</a>, which we don't have enough time to explain here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we've learned that the layers are combined together: <b>convolutional + ReLU + pooling</b> constitute the first part while <b>fully connected</b> the second. One note is that each part can be applied multiple times, as we can see in [the overview of a CNN at the beginning](#conv_image)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keras also provides useful methods to create a CNN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing dependencies\n",
    "import numpy\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Flatten\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.convolutional import MaxPooling2D\n",
    "from keras.utils import np_utils\n",
    "from keras import backend as K\n",
    "K.set_image_dim_ordering('th')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In Keras, the layers used for two-dimensional convolutions expect pixel values with the dimensions [pixels][width][height]. We'll set the pixels dimension to 1 because the pixel values in MNIST are gray scale. As a reminder, all images in MNIST are 28x28."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "\n",
    "# reshape to [samples][pixels][width][height]\n",
    "X_train = X_train.reshape(X_train.shape[0], 1, 28, 28)\n",
    "X_test = X_test.reshape(X_test.shape[0], 1, 28, 28)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below, fill out the blanks to normalize the datasets and one hot encode the output values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize inputs from 0-255 to 0-1\n",
    "X_train = X_train / 255\n",
    "X_test = X_test / 255\n",
    "# one hot encode outputs\n",
    "y_train = np_utils.to_categorical(y_train)\n",
    "y_test = np_utils.to_categorical(y_test)\n",
    "num_classes = y_test.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's define a function that creates our CNN. Read through the comments to understand what each line does."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CNN_model():\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    \n",
    "    # A convolutional layer that has 32 features of size 5x5\n",
    "    model.add(Conv2D(32, (5, 5), input_shape=(1, 28, 28), activation='relu'))\n",
    "    \n",
    "    # A pooling layer with a window size of 2x2\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    \n",
    "    # A dropout layer that randomly excludes 20% of neurons in the layer \n",
    "    model.add(Dropout(0.2))\n",
    "    \n",
    "    # A flatten layer\n",
    "    model.add(Flatten())\n",
    "    \n",
    "    # A fully connected layer with 128 neurons\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    \n",
    "    # An output layer with softmax as in MLP\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "    \n",
    "    # Compile model as before in MLP\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/jmarshall/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 95s - loss: 0.2404 - acc: 0.9314 - val_loss: 0.0785 - val_acc: 0.9762\n",
      "Epoch 2/10\n",
      " - 89s - loss: 0.0755 - acc: 0.9778 - val_loss: 0.0507 - val_acc: 0.9841\n",
      "Epoch 3/10\n",
      " - 87s - loss: 0.0542 - acc: 0.9835 - val_loss: 0.0414 - val_acc: 0.9858\n",
      "Epoch 4/10\n",
      " - 88s - loss: 0.0425 - acc: 0.9869 - val_loss: 0.0381 - val_acc: 0.9868\n",
      "Epoch 5/10\n",
      " - 87s - loss: 0.0336 - acc: 0.9900 - val_loss: 0.0332 - val_acc: 0.9882\n",
      "Epoch 6/10\n",
      " - 95s - loss: 0.0289 - acc: 0.9907 - val_loss: 0.0345 - val_acc: 0.9883\n",
      "Epoch 7/10\n",
      " - 89s - loss: 0.0224 - acc: 0.9932 - val_loss: 0.0294 - val_acc: 0.9890\n",
      "Epoch 8/10\n",
      " - 91s - loss: 0.0208 - acc: 0.9932 - val_loss: 0.0346 - val_acc: 0.9883\n",
      "Epoch 9/10\n",
      " - 92s - loss: 0.0181 - acc: 0.9939 - val_loss: 0.0310 - val_acc: 0.9900\n",
      "Epoch 10/10\n",
      " - 95s - loss: 0.0141 - acc: 0.9955 - val_loss: 0.0333 - val_acc: 0.9903\n",
      "CNN Error: 0.97%\n"
     ]
    }
   ],
   "source": [
    "model = CNN_model()\n",
    "# Fit the model\n",
    "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=10, batch_size=200, verbose=2)\n",
    "\n",
    "# Evaluation of the model\n",
    "scores = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(\"CNN Error: %.2f%%\" % (100-scores[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's experiment with the parameters: number of features, size of features, size of the window in pooling, dropout percentage, and so on. Modify the parameters to your best judgment in the function below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def diff_CNN_model():\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    \n",
    "    # A convolutional layer that has 16 features of size 5x5\n",
    "    model.add(Conv2D(16, (5, 5), input_shape=(1, 28, 28), activation='relu'))\n",
    "    \n",
    "    # A pooling layer with a window size of 2x2\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    \n",
    "    # A dropout layer that randomly excludes 20% of neurons in the layer \n",
    "    model.add(Dropout(0.2))\n",
    "    \n",
    "    # A flatten layer\n",
    "    model.add(Flatten())\n",
    "    \n",
    "    # A fully connected layer with 128 neurons\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    \n",
    "    # An output layer with softmax as in MLP\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "    \n",
    "    # Compile model as before in MLP\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 54s - loss: 0.2879 - acc: 0.9197 - val_loss: 0.0950 - val_acc: 0.9727\n",
      "Epoch 2/10\n",
      " - 49s - loss: 0.0911 - acc: 0.9737 - val_loss: 0.0597 - val_acc: 0.9810\n",
      "Epoch 3/10\n",
      " - 49s - loss: 0.0629 - acc: 0.9813 - val_loss: 0.0470 - val_acc: 0.9845\n",
      "Epoch 4/10\n",
      " - 50s - loss: 0.0510 - acc: 0.9844 - val_loss: 0.0422 - val_acc: 0.9860\n",
      "Epoch 5/10\n",
      " - 48s - loss: 0.0416 - acc: 0.9874 - val_loss: 0.0354 - val_acc: 0.9878\n",
      "Epoch 6/10\n",
      " - 47s - loss: 0.0354 - acc: 0.9889 - val_loss: 0.0337 - val_acc: 0.9892\n",
      "Epoch 7/10\n",
      " - 50s - loss: 0.0300 - acc: 0.9904 - val_loss: 0.0344 - val_acc: 0.9889\n",
      "Epoch 8/10\n",
      " - 51s - loss: 0.0257 - acc: 0.9915 - val_loss: 0.0313 - val_acc: 0.9903\n",
      "Epoch 9/10\n",
      " - 51s - loss: 0.0228 - acc: 0.9928 - val_loss: 0.0319 - val_acc: 0.9913\n",
      "Epoch 10/10\n",
      " - 55s - loss: 0.0206 - acc: 0.9932 - val_loss: 0.0330 - val_acc: 0.9894\n",
      "CNN Error: 1.06%\n"
     ]
    }
   ],
   "source": [
    "model = diff_CNN_model()\n",
    "# Fit the model\n",
    "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=10, batch_size=200, verbose=2)\n",
    "\n",
    "# Evaluation of the model\n",
    "scores = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(\"CNN Error: %.2f%%\" % (100-scores[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do you get different accuracies for the two different models? Make some conclusions about different parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<i>Your Answer Here</i> <b>Allowing fewer features in the convolutional layer sped the algorithm up and didn't make that much difference in terms of accuracy--the error rate was still about 1%. My guess is that you could make it considerably less computationally intensive before the error rate started rising, and that if you added more features or anything else you would not make it much more accurate.</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def more_diff_CNN_model():\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    \n",
    "    # A convolutional layer that has 16 features of size 6x6\n",
    "    model.add(Conv2D(16, (6, 6), input_shape=(1, 28, 28), activation='relu'))\n",
    "    \n",
    "    # A pooling layer with a window size of 2x2\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    \n",
    "    # A dropout layer that randomly excludes 20% of neurons in the layer \n",
    "    model.add(Dropout(0.2))\n",
    "    \n",
    "    # A flatten layer\n",
    "    model.add(Flatten())\n",
    "    \n",
    "    # A fully connected layer with 128 neurons\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    \n",
    "    # An output layer with softmax as in MLP\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "    \n",
    "    # Compile model as before in MLP\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 51s - loss: 0.3091 - acc: 0.9120 - val_loss: 0.1045 - val_acc: 0.9690\n",
      "Epoch 2/10\n",
      " - 50s - loss: 0.0965 - acc: 0.9712 - val_loss: 0.0596 - val_acc: 0.9814\n",
      "Epoch 3/10\n",
      " - 50s - loss: 0.0676 - acc: 0.9789 - val_loss: 0.0499 - val_acc: 0.9832\n",
      "Epoch 4/10\n",
      " - 51s - loss: 0.0529 - acc: 0.9835 - val_loss: 0.0434 - val_acc: 0.9867\n",
      "Epoch 5/10\n",
      " - 47s - loss: 0.0447 - acc: 0.9862 - val_loss: 0.0400 - val_acc: 0.9869\n",
      "Epoch 6/10\n",
      " - 52s - loss: 0.0386 - acc: 0.9877 - val_loss: 0.0344 - val_acc: 0.9879\n",
      "Epoch 7/10\n",
      " - 52s - loss: 0.0311 - acc: 0.9900 - val_loss: 0.0333 - val_acc: 0.9884\n",
      "Epoch 8/10\n",
      " - 48s - loss: 0.0284 - acc: 0.9904 - val_loss: 0.0350 - val_acc: 0.9879\n",
      "Epoch 9/10\n",
      " - 50s - loss: 0.0249 - acc: 0.9921 - val_loss: 0.0356 - val_acc: 0.9889\n",
      "Epoch 10/10\n",
      " - 50s - loss: 0.0225 - acc: 0.9929 - val_loss: 0.0315 - val_acc: 0.9897\n",
      "CNN Error: 1.03%\n"
     ]
    }
   ],
   "source": [
    "model = more_diff_CNN_model()\n",
    "# Fit the model\n",
    "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=10, batch_size=200, verbose=2)\n",
    "\n",
    "# Evaluation of the model\n",
    "scores = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(\"CNN Error: %.2f%%\" % (100-scores[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bibliography"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Image source:\n",
    "- How Convolutional Neural Networks work, https://www.youtube.com/watch?v=FmpDIaiMIeA&t=1070s\n",
    "\n",
    "Code source:\n",
    "- Handwritten Digit Recognition using Convolutional Neural Networks in Python with Keras, https://machinelearningmastery.com/handwritten-digit-recognition-using-convolutional-neural-networks-python-keras/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "Notebook developed by: Tian Qin\n",
    "\n",
    "Data Science Modules: http://data.berkeley.edu/education/modules\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
